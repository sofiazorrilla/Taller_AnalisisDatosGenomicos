---
title: "Procesamiento de VCF: Filtros básicos"
format: html
author: "Sergio y Sofía"
self-contained: true
#keep-md: true
---

## Filtros con vcftools
#---
#Goals: Execute filtering steps for genomic SNP data using primarily VCFTOOLS
# Remove linked SNPs with PLIK
#---

# PART ONE: Filtering SNP data with VCFtools
## BASIC SYNTAX OF VCFTOOLS
vcftools [ --vcf FILE | --gzvcf FILE | --bcf FILE] [ --out OUTPUT PREFIX ] [ FILTERING OPTIONS ] [ OUTPUT OPTIONS ]

#example
SYNTAX OF COMMAND WITH FILTERING CRITERIA AND MISSING CRITERION 30%
vcftools --vcf data2.vcf --remove-indels --hwe --thin 128 --minQ 30 --min-alleles 2 --max-alleles 2 --maf 0.05 --max-missing 0.7 --recode --recode-INFO-all --out missing30samtools.vcf

#Let's try a filtering exercise with only 10% missing data (call rate) and apply to this dataset additional filters outside vcftools for analyses ready vcf
# which will correspond to extremely high depth loci and H-W if in all populations
# MAC = 5 instead of MAF will be used
#removing high missing data individuals and high missing data loci should be done after filtering for min and mean read depths

 
conda activate vcf_env
vcftools --vcf data2.vcf --minQ 10 --min-alleles 2 --max-alleles 2 --mac 5 --min-meanDP 15 --minDP 10 --recode --recode-INFO-all --out no-thinning

#Then we apply the filter for allowing only less than 10% missing data loci, and thin to allow one SNP per RAD-seq loci
vcftools --vcf no-thinnig.recode.vcf --thin 200 --max-missing 0.9 --recode --recode-INFO-all --out missing10-no-hwe

#let's check for proportion of missing data in individuals and remove samples with > 20% missing data

vcftools --vcf missing10-no-hwe.recode.vcf --missing-indv --out missing10-inds
less missing10-inds.imiss

#if any individual has high amounts of missing data
# remove individual from subsequent analyses with --remove-indv
#example: vcftools --vcf missing10.recode.vcf --remove-indv SKC_4 --recode --recode-INFO-all --out missing10_removed

#In the following steps we are going to (i) eliminate extremely high depth loci and (ii) out of H-W eq. loci shared shared among all populations

(i) High depth LOCI
# create a list of the depth of each loci
cut -f8 missing10-no-hwe.recode.vcf | grep -oe "DP=[0-9]*" | sed -s 's/DP=//g' > missing10-no-hwe.DEPTH

#Calculate mean depths
mawk '{ sum += $1; n++ } END { if (n > 0) print sum / n; }' missing10-no-hwe.DEPTH

# Mean depth per site
mawk '!/D/' missing10-no-hwe.DEPTH | mawk -v x=90 '{print $1/x}' > meandepthpersite

#Plot mean depth

gnuplot << \EOF
set terminal dumb size 120, 30
set autoscale
set xrange [10:150]
unset label
set title "Histogram of mean depth per site"
set ylabel "Number of Occurrences"
set xlabel "Mean Depth"
binwidth=1
bin(x,width)=width*floor(x/width) + binwidth/2.0
set xtics 5
plot 'meandepthpersite' using (bin($1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF

#Remove --max-meanDP 100
vcftools --vcf missing10-no-hwe.recode.vcf --recode-INFO-all --out missing10noHDPnoHWE --max-meanDP 100 --recode

# Now we will apply a H-We filter, to remove variants that are out of H-We in every population

# First download the perl script designed for this purposes

curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/filter_hwe_by_pop.pl
chmod +x filter_hwe_by_pop.pl

./filter_hwe_by_pop.pl
 Usage:
     filter_hwe_by_pop.pl -v <vcffile> -p <popmap> [options]

     Options: -v <vcffile> input vcf file -p <popmap> tab-separated file of
     samples and population designations -h [hwe] minimum Hardy-Weinberg
     p-value cutoff for SNPs -c [cutoff] proportion of all populations that a
     locus can be below HWE cutoff without being filtered -o [out] name of
     outfile

 Options:
     -v, --vcffile
             VCF input file

     -p, --popmap
             File with names of individuals and population designations, one
             per line

     -h, --hwe
             Minimum cutoff for Hardy-Weinberg p-value (for test as
             implemented in vcftools) [Default: 0.001]

     -c, --cutoff
             Proportion of all populations that a locus can be below HWE
             cutoff without being filtered. For example, choosing 0.5 will
             filter SNPs that are below the p-value threshold in 50% or more
             of the populations. [Default: 0.25]

     -o, --out
             Name of outfile, by vcftools conventions (will be named
             X.recode.vcf
             
# If your dataset contains indels then remove them with vcftools.
# Create a population map, first column sample name and second column population initials (no header required)
# Removing out of H-W LOCI
# activate vcftools environment in conda before executing

./filter_hwe_by_pop.pl -v missing10preHWfilter.vcf -p pop_map.txt -o filteredSNP_Ipyrad -h 0.005 -c 0.95
vcftools --vcf filteredSNP_Ipyrad.recode.vcf --missing-indv --out missingSNPIpyrad
less missingSNPIpyrad.imiss

#----
#--- PART TWO: Removing linked SNP data with PLINK

#Load conda environment for PLINK

# perform linkage pruning - i.e. identify prune sites
plink --vcf file.vcf --double-id --allow-extra-chr \
--set-missing-var-ids @:# \
--indep-pairwise 50 10 0.5 --out Pruned_SNP

FILE=Pruned_SNP 

#prune linked loci  (use prune.in file in that folder)
plink --bfile $FILE --extract ../Pruned_SNP.prune.in --make-bed --out unlinked_file --allow-extra-chr

#Then we convert bed file to VCF file for analyses-ready vcf

plink --bfile Pruned_SNP --recode vcf --out Analyses_ready


## Filtros con SNPFiltR




